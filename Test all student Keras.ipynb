{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import time\n",
    "import random\n",
    "import sys\n",
    "# Import T. Kipf's GCN implementation\n",
    "# https://github.com/tkipf/keras-gcn\n",
    "sys.path.append('./keras-gcn/')\n",
    "from keras.layers import Input, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from kegra.layers.graph import GraphConvolution\n",
    "from kegra.utils import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.read_hdf('history_small.hdf', key='hist') \n",
    "A = pd.read_pickle('adjacency_small.pkl') \n",
    "A = A[sorted(A.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((878, 290), (878, 878))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, A.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1, 10])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[X==1] = 10 #valid\n",
    "X[X==0] = 1 #not valid\n",
    "X[X==-100] = 0 #missing\n",
    "np.unique(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = X.values.ravel(order = 'F') #len(y) =n*m : 878*290 #rempli en colonne de sorte que \n",
    "                                        #per user_id, the responses to all the exercise_id (valid/not valid/missing)\n",
    "#np.where(y!=0)[0].shape #8821 non null entries (1 or 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = []\n",
    "for col in X : \n",
    "    a = pd.get_dummies(X[col])\n",
    "    if (1 not in a.columns) & (10 in a.columns):\n",
    "        a[1] = np.zeros(a.shape[0],dtype=int)\n",
    "    if (1 in a.columns) & (10 not in a.columns):\n",
    "        a[10] = np.zeros(a.shape[0],dtype=int)\n",
    "    l.append(a[[1,10]])\n",
    "X = pd.concat(l, axis=1, keys=X.columns)\n",
    "X.columns = [str(int(col[0]))+'_'+str(col[1]) for col in X.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = scipy.sparse.csr_matrix(A.values)\n",
    "X = np.asmatrix(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(878, 580) (878, 878) (254620,)\n",
      "<class 'numpy.matrixlib.defmatrix.matrix'> <class 'scipy.sparse.csr.csr_matrix'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, A.shape, y.shape) #n*2m, n*m\n",
    "print(type(X), type(A), type(y)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_mask(idx, l):\n",
    "    mask = np.zeros(l)\n",
    "    mask[idx] = 1\n",
    "    return np.array(mask, dtype=np.bool)\n",
    "\n",
    "def get_splits(y):\n",
    "    idx_train = range(878)\n",
    "    idx_val = range(878)#range(878, 1756)\n",
    "    idx_test = range(878)#range(1756, 2634)\n",
    "    y_train = np.zeros(len(idx_train), dtype=np.int32)\n",
    "    y_val = np.zeros(len(idx_val), dtype=np.int32)\n",
    "    y_test = np.zeros(len(idx_test), dtype=np.int32)\n",
    "    y_train = y[idx_train]\n",
    "    y_val = y[idx_val]\n",
    "    y_test = y[idx_test]\n",
    "    train_mask = np.array(np.ones(len(range(878))), dtype=np.bool)\n",
    "    return y_train, y_val, y_test, idx_train, idx_val, idx_test, train_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train, y_val, y_test, idx_train, idx_val, idx_test, train_mask = get_splits(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FILTER = 'localpool'  \n",
    "MAX_DEGREE = 2 \n",
    "SYM_NORM = True  \n",
    "NB_EPOCH = 200\n",
    "PATIENCE = 10  \n",
    "\n",
    "# Normalize X\n",
    "X = X/(X.sum(1).reshape(-1, 1))\n",
    "\n",
    "A_ = preprocess_adj(A, SYM_NORM)\n",
    "support = 1\n",
    "graph = [X, A_]\n",
    "G = [Input(shape=(None, None), batch_shape=(None, None), sparse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_in = Input(shape=(X.shape[1],))\n",
    "H = Dropout(0.5)(X_in)\n",
    "H = GraphConvolution(16, support, activation='relu', W_regularizer=l2(5e-4))([H]+G)\n",
    "H = Dropout(0.5)(H)\n",
    "Y = GraphConvolution(1, support, activation='softmax')([H]+G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_(y_true, y_pred):\n",
    "    ix = tf.where(tf.not_equal(y_true, 0))\n",
    "    true = tf.gather(y_true, ix)\n",
    "    pred = tf.gather(y_pred, ix)\n",
    "    return K.binary_crossentropy(true, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model = Model(inputs=[X_in]+G, outputs=Y)\n",
    "model.compile(loss=loss_, optimizer=Adam(lr=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wait = 0\n",
    "preds = None\n",
    "best_val_loss = 99999\n",
    "\n",
    "# Fit\n",
    "for epoch in range(1, NB_EPOCH+1):\n",
    "    t = time.time()\n",
    "    model.fit(graph, y_train, sample_weight=train_mask,\n",
    "              batch_size=A.shape[0], epochs=1, shuffle=False, verbose=1)\n",
    "    preds = model.predict(graph, batch_size=A.shape[0])\n",
    "    \n",
    "    # Train / validation scores\n",
    "    train_val_loss, train_val_acc = evaluate_preds(preds, [y_train, y_val],\n",
    "                                                   [idx_train, idx_val])\n",
    "    print(\"Epoch: {:04d}\".format(epoch),\n",
    "          \"train_loss= {:.4f}\".format(train_val_loss[0]),\n",
    "          \"train_acc= {:.4f}\".format(train_val_acc[0]),\n",
    "          \"val_loss= {:.4f}\".format(train_val_loss[1]),\n",
    "          \"val_acc= {:.4f}\".format(train_val_acc[1]),\n",
    "          \"time= {:.4f}\".format(time.time() - t))\n",
    "\n",
    "    # Early stopping\n",
    "    if train_val_loss[1] < best_val_loss:\n",
    "        best_val_loss = train_val_loss[1]\n",
    "        wait = 0\n",
    "    else:\n",
    "        if wait >= PATIENCE:\n",
    "            print('Epoch {}: early stopping'.format(epoch))\n",
    "            break\n",
    "        wait += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testing\n",
    "test_loss, test_acc = evaluate_preds(preds, [y_test], [idx_test])\n",
    "print(\"Test set results:\",\n",
    "      \"loss= {:.4f}\".format(test_loss[0]),\n",
    "      \"accuracy= {:.4f}\".format(test_acc[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
