{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T18:47:18.850263Z",
     "start_time": "2017-12-28T18:47:18.838281Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import time\n",
    "import random\n",
    "import sys\n",
    "# Import T. Kipf's GCN implementation\n",
    "# https://github.com/tkipf/keras-gcn\n",
    "sys.path.append('./keras-gcn/')\n",
    "from keras.layers import Input, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from kegra.layers.graph import GraphConvolution\n",
    "from kegra.utils import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = pd.read_hdf('history_small.hdf', key='hist') \n",
    "A = pd.read_pickle('adjacency_small.pkl') \n",
    "A = A[sorted(A.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((878, 290), (878, 878))"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, A.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One student and all the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "student = 142954.0\n",
    "X_k_ = X[student]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_k_[X_k_==1] = 10 #valid\n",
    "X_k_[X_k_==0] = 1 #not valid\n",
    "X_k_[X_k_==-100] = 0 #missing\n",
    "np.unique(X_k_)\n",
    "X = pd.get_dummies(X_k_)[[1,10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = X_k_.ravel(order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = scipy.sparse.csr_matrix(A.values)\n",
    "X = np.asmatrix(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([327, 328, 330, 333, 338, 340, 347, 349, 352, 355, 358, 364, 371,\n",
       "       372, 380, 381, 385, 387, 436, 442])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind, _ = np.where(X!=0)\n",
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for training no missing value\n",
    "#x_k_ = X_k_[X_k_!=0]\n",
    "#X = pd.get_dummies(x_k_)\n",
    "#A = A[ind][:,ind]\n",
    "#y = y[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(878, 2) (878, 878) (878,)\n",
      "<class 'numpy.matrixlib.defmatrix.matrix'> <class 'scipy.sparse.csr.csr_matrix'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, A.shape, y.shape)\n",
    "print(type(X), type(A), type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#A = A[ind][:,ind]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def get_splits(y):\n",
    "    idx_train = sorted(random.sample(list(ind), 15))\n",
    "    idx_val = sorted([k for k in ind if k not in idx_train])\n",
    "    idx_test = sorted([k for k in range(878) if k not in ind])\n",
    "    y_train = np.zeros(y.shape, dtype=np.int32)\n",
    "    y_val = np.zeros(y.shape, dtype=np.int32)\n",
    "    y_test = np.zeros(y.shape, dtype=np.int32)\n",
    "    y_train[idx_train] = y[idx_train]\n",
    "    y_val[idx_val] = y[idx_val]\n",
    "    y_test[idx_test] = y[idx_test]\n",
    "    train_mask = sample_mask(idx_train, y.shape[0])\n",
    "    return y_train, y_val, y_test, idx_train, idx_val, idx_test, train_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train = y.reshape(878,1)\n",
    "y_val = y.reshape(878,1)\n",
    "y_test = y.reshape(878,1)\n",
    "idx_train = range(878)\n",
    "idx_test = range(878)\n",
    "idx_val = range(878)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Normalize X ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "FILTER = 'localpool'  # 'chebyshev'\n",
    "MAX_DEGREE = 2  # maximum polynomial degree\n",
    "SYM_NORM = True  # symmetric (True) vs. left-only (False) normalization\n",
    "NB_EPOCH = 200\n",
    "PATIENCE = 10  # early stopping patience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A_ = preprocess_adj(A, SYM_NORM)\n",
    "support = 1\n",
    "graph = [X, A_]\n",
    "G = [Input(shape=(None, None), batch_shape=(None, None), sparse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_in = Input(shape=(X.shape[1],))\n",
    "H = Dropout(0.5)(X_in)\n",
    "H = GraphConvolution(16, support, activation='relu', W_regularizer=l2(5e-4))([H]+G)\n",
    "H = Dropout(0.5)(H)\n",
    "Y = GraphConvolution(1, support, activation='softmax')([H]+G)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def get_loss(mask_value):\n",
    "    mask_value = K.variable(mask_value)\n",
    "    def masked_binary_crossentropy(y_true, y_pred):\n",
    "        # find out which timesteps in `y_true` are not the padding character '#'\n",
    "        mask = K.all(K.equal(y_true, mask_value), axis=-1)\n",
    "        mask = 1 - K.cast(mask, K.floatx())\n",
    "        # multiply categorical_crossentropy with the mask\n",
    "        loss = K.binary_crossentropy(y_true, y_pred) * mask\n",
    "        # take average w.r.t. the number of unmasked entries\n",
    "        return K.sum(loss) / K.sum(mask)\n",
    "    return masked_binary_crossentropy\n",
    "\n",
    "masked_binary_crossentropy = get_loss([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loss_(y_true, y_pred):\n",
    "    ix = tf.where(tf.not_equal(y_true, 0))\n",
    "    true = tf.gather(y_true, ix)\n",
    "    pred = tf.gather(y_pred, ix)\n",
    "    print(true)\n",
    "    print(pred)\n",
    "    return K.binary_crossentropy(true, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    ix = tf.where(tf.not_equal(y_true, 0))\n",
    "    y_true = tf.gather(y_true, ix)\n",
    "    y_true = K.concatenate([y_true, y_true], axis=0)\n",
    "\n",
    "    y_pred = tf.gather(y_pred, ix)\n",
    "    y_pred = K.concatenate([y_pred, y_pred], axis=0)\n",
    "\n",
    "    return K.binary_crossentropy(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"loss_9/graph_convolution_14_loss/Gather:0\", shape=(?, 2, ?), dtype=float32)\n",
      "Tensor(\"loss_9/graph_convolution_14_loss/Gather_1:0\", shape=(?, 2, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model = Model(inputs=[X_in]+G, outputs=Y)\n",
    "model.compile(loss=loss_, optimizer=Adam(lr=0.01)) #adapt crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [20] vs. [878]\n\t [[Node: training_5/Adam/gradients/loss_9/graph_convolution_14_loss/mul_grad/BroadcastGradientArgs = BroadcastGradientArgs[T=DT_INT32, _class=[\"loc:@loss_9/graph_convolution_14_loss/mul\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](training_5/Adam/gradients/loss_9/graph_convolution_14_loss/mul_grad/Shape, training_5/Adam/gradients/loss_9/graph_convolution_14_loss/mul_grad/Shape_1)]]\n\nCaused by op 'training_5/Adam/gradients/loss_9/graph_convolution_14_loss/mul_grad/BroadcastGradientArgs', defined at:\n  File \"//anaconda/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"//anaconda/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"//anaconda/lib/python3.5/site-packages/traitlets/config/application.py\", line 589, in launch_instance\n    app.start()\n  File \"//anaconda/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 405, in start\n    ioloop.IOLoop.instance().start()\n  File \"//anaconda/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"//anaconda/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"//anaconda/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"//anaconda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"//anaconda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"//anaconda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"//anaconda/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"//anaconda/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 260, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"//anaconda/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 212, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"//anaconda/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 370, in execute_request\n    user_expressions, allow_stdin)\n  File \"//anaconda/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 175, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"//anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2902, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"//anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"//anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3066, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-151-6bcfd1dee675>\", line 14, in <module>\n    batch_size=A.shape[0], epochs=1, shuffle=False, verbose=1)\n  File \"/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/keras/engine/training.py\", line 1634, in fit\n    self._make_train_function()\n  File \"/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/keras/engine/training.py\", line 990, in _make_train_function\n    loss=self.total_loss)\n  File \"/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/keras/legacy/interfaces.py\", line 87, in wrapper\n    return func(*args, **kwargs)\n  File \"/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/keras/optimizers.py\", line 415, in get_updates\n    grads = self.get_gradients(loss, params)\n  File \"/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/keras/optimizers.py\", line 73, in get_gradients\n    grads = K.gradients(loss, params)\n  File \"/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 2394, in gradients\n    return tf.gradients(loss, variables, colocate_gradients_with_ops=True)\n  File \"/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py\", line 581, in gradients\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py\", line 353, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py\", line 581, in <lambda>\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/math_grad.py\", line 742, in _MulGrad\n    rx, ry = gen_array_ops._broadcast_gradient_args(sx, sy)\n  File \"/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 532, in _broadcast_gradient_args\n    \"BroadcastGradientArgs\", s0=s0, s1=s1, name=name)\n  File \"/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\n...which was originally created as op 'loss_9/graph_convolution_14_loss/mul', defined at:\n  File \"//anaconda/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 15 identical lines from previous traceback]\n  File \"//anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2902, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"//anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3012, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"//anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3066, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-150-17d13fd5efee>\", line 3, in <module>\n    model.compile(loss=loss_, optimizer=Adam(lr=0.01)) #adapt crossentropy\n  File \"/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/keras/engine/training.py\", line 860, in compile\n    sample_weight, mask)\n  File \"/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/keras/engine/training.py\", line 475, in weighted\n    score_array *= weights\n  File \"/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\", line 894, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\", line 1117, in _mul_dispatch\n    return gen_math_ops._mul(x, y, name=name)\n  File \"/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 2726, in _mul\n    \"Mul\", x=x, y=y, name=name)\n  File \"/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Incompatible shapes: [20] vs. [878]\n\t [[Node: training_5/Adam/gradients/loss_9/graph_convolution_14_loss/mul_grad/BroadcastGradientArgs = BroadcastGradientArgs[T=DT_INT32, _class=[\"loc:@loss_9/graph_convolution_14_loss/mul\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](training_5/Adam/gradients/loss_9/graph_convolution_14_loss/mul_grad/Shape, training_5/Adam/gradients/loss_9/graph_convolution_14_loss/mul_grad/Shape_1)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [20] vs. [878]\n\t [[Node: training_5/Adam/gradients/loss_9/graph_convolution_14_loss/mul_grad/BroadcastGradientArgs = BroadcastGradientArgs[T=DT_INT32, _class=[\"loc:@loss_9/graph_convolution_14_loss/mul\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](training_5/Adam/gradients/loss_9/graph_convolution_14_loss/mul_grad/Shape, training_5/Adam/gradients/loss_9/graph_convolution_14_loss/mul_grad/Shape_1)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-151-6bcfd1dee675>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Single training iteration (we mask nodes without labels for loss calculation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     model.fit(graph, y_train, #sample_weight=train_mask,\n\u001b[0;32m---> 14\u001b[0;31m               batch_size=A.shape[0], epochs=1, shuffle=False, verbose=1)\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Predict on full dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [20] vs. [878]\n\t [[Node: training_5/Adam/gradients/loss_9/graph_convolution_14_loss/mul_grad/BroadcastGradientArgs = BroadcastGradientArgs[T=DT_INT32, _class=[\"loc:@loss_9/graph_convolution_14_loss/mul\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](training_5/Adam/gradients/loss_9/graph_convolution_14_loss/mul_grad/Shape, training_5/Adam/gradients/loss_9/graph_convolution_14_loss/mul_grad/Shape_1)]]\n\nCaused by op 'training_5/Adam/gradients/loss_9/graph_convolution_14_loss/mul_grad/BroadcastGradientArgs', defined at:\n  File \"//anaconda/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"//anaconda/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"//anaconda/lib/python3.5/site-packages/traitlets/config/application.py\", line 589, in launch_instance\n    app.start()\n  File \"//anaconda/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 405, in start\n    ioloop.IOLoop.instance().start()\n  File \"//anaconda/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"//anaconda/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"//anaconda/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"//anaconda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"//anaconda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"//anaconda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"//anaconda/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"//anaconda/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 260, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"//anaconda/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 212, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"//anaconda/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 370, in execute_request\n    user_expressions, allow_stdin)\n  File \"//anaconda/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 175, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"//anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2902, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"//anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"//anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3066, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-151-6bcfd1dee675>\", line 14, in <module>\n    batch_size=A.shape[0], epochs=1, shuffle=False, verbose=1)\n  File \"/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/keras/engine/training.py\", line 1634, in fit\n    self._make_train_function()\n  File \"/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/keras/engine/training.py\", line 990, in _make_train_function\n    loss=self.total_loss)\n  File \"/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/keras/legacy/interfaces.py\", line 87, in wrapper\n    return func(*args, **kwargs)\n  File \"/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/keras/optimizers.py\", line 415, in get_updates\n    grads = self.get_gradients(loss, params)\n  File \"/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/keras/optimizers.py\", line 73, in get_gradients\n    grads = K.gradients(loss, params)\n  File \"/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 2394, in gradients\n    return tf.gradients(loss, variables, colocate_gradients_with_ops=True)\n  File \"/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py\", line 581, in gradients\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py\", line 353, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py\", line 581, in <lambda>\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/math_grad.py\", line 742, in _MulGrad\n    rx, ry = gen_array_ops._broadcast_gradient_args(sx, sy)\n  File \"/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 532, in _broadcast_gradient_args\n    \"BroadcastGradientArgs\", s0=s0, s1=s1, name=name)\n  File \"/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\n...which was originally created as op 'loss_9/graph_convolution_14_loss/mul', defined at:\n  File \"//anaconda/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 15 identical lines from previous traceback]\n  File \"//anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2902, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"//anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3012, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"//anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3066, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-150-17d13fd5efee>\", line 3, in <module>\n    model.compile(loss=loss_, optimizer=Adam(lr=0.01)) #adapt crossentropy\n  File \"/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/keras/engine/training.py\", line 860, in compile\n    sample_weight, mask)\n  File \"/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/keras/engine/training.py\", line 475, in weighted\n    score_array *= weights\n  File \"/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\", line 894, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\", line 1117, in _mul_dispatch\n    return gen_math_ops._mul(x, y, name=name)\n  File \"/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 2726, in _mul\n    \"Mul\", x=x, y=y, name=name)\n  File \"/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Incompatible shapes: [20] vs. [878]\n\t [[Node: training_5/Adam/gradients/loss_9/graph_convolution_14_loss/mul_grad/BroadcastGradientArgs = BroadcastGradientArgs[T=DT_INT32, _class=[\"loc:@loss_9/graph_convolution_14_loss/mul\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](training_5/Adam/gradients/loss_9/graph_convolution_14_loss/mul_grad/Shape, training_5/Adam/gradients/loss_9/graph_convolution_14_loss/mul_grad/Shape_1)]]\n"
     ]
    }
   ],
   "source": [
    "# Helper variables for main training loop\n",
    "wait = 0\n",
    "preds = None\n",
    "best_val_loss = 99999\n",
    "\n",
    "# Fit\n",
    "for epoch in range(1, NB_EPOCH+1):\n",
    "\n",
    "    # Log wall-clock time\n",
    "    t = time.time()\n",
    "\n",
    "    # Single training iteration (we mask nodes without labels for loss calculation)\n",
    "    model.fit(graph, y_train, #sample_weight=train_mask,\n",
    "              batch_size=A.shape[0], epochs=1, shuffle=False, verbose=1)\n",
    "\n",
    "    # Predict on full dataset\n",
    "    preds = model.predict(graph, batch_size=A.shape[0])\n",
    "    \n",
    "    # Train / validation scores\n",
    "    train_val_loss, train_val_acc = evaluate_preds(preds, [y_train, y_val],\n",
    "                                                   [idx_train, idx_val])\n",
    "    print(\"Epoch: {:04d}\".format(epoch),\n",
    "          \"train_loss= {:.4f}\".format(train_val_loss[0]),\n",
    "          \"train_acc= {:.4f}\".format(train_val_acc[0]),\n",
    "          \"val_loss= {:.4f}\".format(train_val_loss[1]),\n",
    "          \"val_acc= {:.4f}\".format(train_val_acc[1]),\n",
    "          \"time= {:.4f}\".format(time.time() - t))\n",
    "\n",
    "    # Early stopping\n",
    "    if train_val_loss[1] < best_val_loss:\n",
    "        best_val_loss = train_val_loss[1]\n",
    "        wait = 0\n",
    "    else:\n",
    "        if wait >= PATIENCE:\n",
    "            print('Epoch {}: early stopping'.format(epoch))\n",
    "            break\n",
    "        wait += 1\n",
    "\n",
    "# Testing\n",
    "#test_loss, test_acc = evaluate_preds(preds, [y_test], [idx_test])\n",
    "#print(\"Test set results:\",\n",
    "#      \"loss= {:.4f}\".format(test_loss[0]),\n",
    "#      \"accuracy= {:.4f}\".format(test_acc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(index 0 : -100 (NaN), index 1 : 0 (not valid), index 2 : 1 (valid))  \n",
    "index 0 : 0 (not valid), index 1 : 1 (valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds == 1).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "student = 142954.0\n",
    "X_k_ = X[student]\n",
    "X_k, ex_k = X_k_[X_k_!=-100], X_k_[X_k_!=-100].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_samples = 15\n",
    "full = 20\n",
    "\n",
    "X_train = X_k.values.reshape(full,1)\n",
    "y_train = X_k[:full].values.reshape(full,1)\n",
    "\n",
    "A_train = A[A.index.isin(idx_full)][sorted(idx_full)]\n",
    "A_train = scipy.sparse.csr_matrix(A_train.values)\n",
    "\n",
    "train_mask = sample_mask(range(15), A_train.shape[0]).reshape(20,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A_train.shape, X_train.shape, y_train.shape, train_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize X_train\n",
    "X_train = X_train/X_train.sum()\n",
    "X_train = X_train.reshape((len(X_train), 1))\n",
    "\n",
    "A_ = preprocess_adj(A_train, True)\n",
    "support = 1\n",
    "graph = [X_train, A_]\n",
    "G = [Input(shape=(None, None), batch_shape=(None, None), sparse=True)]\n",
    "X_in = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "# Define model architecture\n",
    "H = Dropout(0.5)(X_in)\n",
    "H = GraphConvolution(16, support, activation='relu', W_regularizer=l2(5e-4))([H]+G)\n",
    "H = Dropout(0.5)(H)\n",
    "Y = GraphConvolution(y_train.shape[1], support, activation='softmax')([H]+G)\n",
    "\n",
    "# Compile model\n",
    "model = Model(inputs=[X_in]+G, outputs=Y)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h = model.fit(graph, y_train, #sample_weight=train_mask, \n",
    "          batch_size=A_train.shape[0], epochs=1, shuffle=False, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T18:49:30.604314Z",
     "start_time": "2017-12-28T18:49:30.597102Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "student = 142954.0 # np.random.choice(X.columns)\n",
    "X_k_ = X[student]\n",
    "X_k, ex_k = X_k_[X_k_!=-100], X_k_[X_k_!=-100].index\n",
    "c = 15\n",
    "assert c + 1< len(X_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot(x):\n",
    "    if x == 0:\n",
    "        return [1,0]\n",
    "    elif x == 1:\n",
    "        return [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T19:00:07.339350Z",
     "start_time": "2017-12-28T19:00:07.326173Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_samples = 15\n",
    "idx_train = random.sample(list(ex_k), n_samples)\n",
    "idx_test = random.sample([k for k in ex_k if k not in idx_train], 1)\n",
    "idx_full = np.hstack((idx_train,idx_test))\n",
    "X_train = X_k.loc[idx_full].values\n",
    "#X_train = to_categorical(X_train)\n",
    "#y_train = X_k.loc[idx_test]\n",
    "#y_train = np.array(y_train).reshape((len(y_train), 1))\n",
    "y_train = np.zeros((X_train.shape[0],2))\n",
    "y_train[n_samples] = one_hot(X_train[n_samples])\n",
    "A_train = A[A.index.isin(idx_full)][sorted(idx_full)]\n",
    "A_train = scipy.sparse.csr_matrix(A_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T18:58:46.305179Z",
     "start_time": "2017-12-28T18:58:46.301657Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A_train.shape, X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T19:00:21.748166Z",
     "start_time": "2017-12-28T19:00:21.745513Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_mask = np.array(list(map(bool, np.hstack((np.ones(n_samples), [0])))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T19:00:42.405322Z",
     "start_time": "2017-12-28T19:00:42.402219Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize X_train\n",
    "X_train = X_train/X_train.sum()\n",
    "X_train = X_train.reshape((len(X_train), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T19:00:44.698860Z",
     "start_time": "2017-12-28T19:00:44.689536Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "A_ = preprocess_adj(A_train, True)\n",
    "support = 1\n",
    "graph = [X_train, A_]\n",
    "G = [Input(shape=(None, None), batch_shape=(None, None), sparse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T19:01:03.439748Z",
     "start_time": "2017-12-28T19:01:03.330056Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_in = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "# Define model architecture\n",
    "H = Dropout(0.5)(X_in)\n",
    "H = GraphConvolution(16, support, activation='relu', W_regularizer=l2(5e-4))([H]+G)\n",
    "H = Dropout(0.5)(H)\n",
    "Y = GraphConvolution(y_train.shape[1], support, activation='softmax')([H]+G)\n",
    "\n",
    "# Compile model\n",
    "model = Model(inputs=[X_in]+G, outputs=Y)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T19:01:04.379941Z",
     "start_time": "2017-12-28T19:01:03.642338Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h = model.fit(graph, y_train, sample_weight=train_mask,\n",
    "          batch_size=A_train.shape[0], epochs=1, shuffle=False, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T19:01:05.569414Z",
     "start_time": "2017-12-28T19:01:05.521980Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict(graph, batch_size=A_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T19:01:06.526325Z",
     "start_time": "2017-12-28T19:01:06.521601Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
