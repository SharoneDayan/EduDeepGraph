{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T09:04:46.230853Z",
     "start_time": "2017-12-28T09:04:46.215412Z"
    },
    "collapsed": false
=======
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T18:07:45.612882Z",
     "start_time": "2017-12-28T18:07:43.914139Z"
    }
>>>>>>> fd23bd67918ffef1d184d4c5a1e6ccea23ce3641
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/attia/Desktop/Work/workenv/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics.pairwise import pairwise_distances, euclidean_distances\n",
    "import scipy\n",
    "import sys\n",
    "# Import T. Kipf's GCN implementation\n",
    "# https://github.com/tkipf/keras-gcn\n",
    "sys.path.append('./keras-gcn/')\n",
    "\n",
    "from keras.layers import Input, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import to_categorical\n",
    "import time\n",
    "\n",
    "from kegra.layers.graph import GraphConvolution\n",
    "from kegra.utils import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic usage"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T10:43:00.154656Z",
     "start_time": "2017-12-28T10:43:00.152229Z"
    },
    "collapsed": true
=======
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T18:07:45.617084Z",
     "start_time": "2017-12-28T18:07:45.614657Z"
    }
>>>>>>> fd23bd67918ffef1d184d4c5a1e6ccea23ce3641
   },
   "outputs": [],
   "source": [
    "nodes = 2500\n",
    "n_features = 600"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T10:43:00.910144Z",
     "start_time": "2017-12-28T10:43:00.395274Z"
    },
    "collapsed": true
=======
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T18:07:46.228313Z",
     "start_time": "2017-12-28T18:07:45.618694Z"
    }
>>>>>>> fd23bd67918ffef1d184d4c5a1e6ccea23ce3641
   },
   "outputs": [],
   "source": [
    "# Loading data\n",
    "# X : (nodes, n_features) random features matrix of 0/1\n",
    "X = np.matrix(np.random.choice([0,1], (nodes, n_features)))\n",
    "# A : (nodes, nodes) random adjacency matrix\n",
    "A = scipy.sparse.rand(nodes, nodes, density=0.4, format='csr')\n",
    "A.data[:] = 1\n",
    "# (nodes, 1) vector with the category of each row\n",
    "y = np.random.choice([0,1], nodes).reshape((nodes, 1))\n",
    "# Converts a class vector to binary class matrix.\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T10:43:00.915039Z",
     "start_time": "2017-12-28T10:43:00.911549Z"
    },
    "collapsed": false
=======
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T18:07:46.235135Z",
     "start_time": "2017-12-28T18:07:46.229856Z"
    }
>>>>>>> fd23bd67918ffef1d184d4c5a1e6ccea23ce3641
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2500, 600), (2500, 2500))"
      ]
     },
<<<<<<< HEAD
     "execution_count": 16,
=======
     "execution_count": 4,
>>>>>>> fd23bd67918ffef1d184d4c5a1e6ccea23ce3641
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, A.shape"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T10:43:00.919775Z",
     "start_time": "2017-12-28T10:43:00.916562Z"
    },
    "collapsed": true
=======
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T18:07:46.239684Z",
     "start_time": "2017-12-28T18:07:46.236468Z"
    }
>>>>>>> fd23bd67918ffef1d184d4c5a1e6ccea23ce3641
   },
   "outputs": [],
   "source": [
    "# split for training/validation and testing\n",
    "y_train, y_val, y_test, idx_train, idx_val, idx_test, train_mask = get_splits(y)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       ..., \n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train+y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1480</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1491</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1492</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1494</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>501 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1\n",
       "504   1  0\n",
       "507   1  0\n",
       "508   1  0\n",
       "514   1  0\n",
       "515   1  0\n",
       "518   1  0\n",
       "520   1  0\n",
       "521   1  0\n",
       "523   1  0\n",
       "524   1  0\n",
       "529   1  0\n",
       "530   1  0\n",
       "532   1  0\n",
       "533   1  0\n",
       "534   1  0\n",
       "535   1  0\n",
       "536   1  0\n",
       "537   1  0\n",
       "539   1  0\n",
       "540   1  0\n",
       "542   1  0\n",
       "544   1  0\n",
       "545   1  0\n",
       "546   1  0\n",
       "547   1  0\n",
       "548   1  0\n",
       "550   1  0\n",
       "551   1  0\n",
       "553   1  0\n",
       "554   1  0\n",
       "...  .. ..\n",
       "1436  1  0\n",
       "1437  1  0\n",
       "1440  1  0\n",
       "1445  1  0\n",
       "1449  1  0\n",
       "1450  1  0\n",
       "1451  1  0\n",
       "1453  1  0\n",
       "1456  1  0\n",
       "1459  1  0\n",
       "1461  1  0\n",
       "1462  1  0\n",
       "1464  1  0\n",
       "1467  1  0\n",
       "1468  1  0\n",
       "1470  1  0\n",
       "1471  1  0\n",
       "1472  1  0\n",
       "1478  1  0\n",
       "1480  1  0\n",
       "1482  1  0\n",
       "1485  1  0\n",
       "1486  1  0\n",
       "1488  1  0\n",
       "1489  1  0\n",
       "1491  1  0\n",
       "1492  1  0\n",
       "1494  1  0\n",
       "1495  1  0\n",
       "1498  1  0\n",
       "\n",
       "[501 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd = pd.DataFrame(y_test)\n",
    "dd[dd[0] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ..., False, False, False], dtype=bool)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T10:43:01.129448Z",
     "start_time": "2017-12-28T10:43:01.115799Z"
    },
    "collapsed": true
=======
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T18:07:47.258068Z",
     "start_time": "2017-12-28T18:07:47.246575Z"
    }
>>>>>>> fd23bd67918ffef1d184d4c5a1e6ccea23ce3641
   },
   "outputs": [],
   "source": [
    "# Normalize X \n",
    "X = X/X.sum(1).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T10:43:01.741771Z",
     "start_time": "2017-12-28T10:43:01.619312Z"
    },
    "collapsed": true
=======
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T18:07:47.861369Z",
     "start_time": "2017-12-28T18:07:47.693554Z"
    }
>>>>>>> fd23bd67918ffef1d184d4c5a1e6ccea23ce3641
   },
   "outputs": [],
   "source": [
    "# Local Pooling\n",
    "# Preprocessing A: multiplication with A means that, for every node, we sum up all the feature vectors \n",
    "# of all neighboring nodes but not the node itself (unless there are self-loops in the graph). \n",
    "# We can \"fix\" this by enforcing self-loops in the graph: we simply add the identity matrix to A.\n",
    "A_ = preprocess_adj(A, True)\n",
    "support = 1\n",
    "graph = [X, A_]\n",
    "G = [Input(shape=(None, None), batch_shape=(None, None), sparse=True)]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T10:43:02.367587Z",
     "start_time": "2017-12-28T10:43:02.265133Z"
    },
    "collapsed": true
=======
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T18:07:48.786773Z",
     "start_time": "2017-12-28T18:07:48.662851Z"
    }
>>>>>>> fd23bd67918ffef1d184d4c5a1e6ccea23ce3641
   },
   "outputs": [],
   "source": [
    "X_in = Input(shape=(X.shape[1],))\n",
    "\n",
    "# Define model architecture\n",
    "H = Dropout(0.5)(X_in)\n",
    "H = GraphConvolution(16, support, activation='relu', W_regularizer=l2(5e-4))([H]+G)\n",
    "H = Dropout(0.5)(H)\n",
    "Y = GraphConvolution(y.shape[1], support, activation='softmax')([H]+G)\n",
    "\n",
    "# Compile model\n",
    "model = Model(inputs=[X_in]+G, outputs=Y)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.01))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 21,
=======
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T18:08:00.946651Z",
     "start_time": "2017-12-28T18:08:00.942782Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 0],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        ..., \n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0]], dtype=int32), (2500, 2))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T18:08:50.069062Z",
     "start_time": "2017-12-28T18:08:50.065647Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       ..., \n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
>>>>>>> fd23bd67918ffef1d184d4c5a1e6ccea23ce3641
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T10:43:13.573550Z",
     "start_time": "2017-12-28T10:43:03.026531Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 train_loss= 0.6931 train_acc= 0.4929 val_loss= 0.6931 val_acc= 0.4833 time= 2.2440\n",
      "Epoch: 0002 train_loss= 0.6931 train_acc= 0.5071 val_loss= 0.6931 val_acc= 0.5167 time= 2.0075\n",
      "Epoch: 0003 train_loss= 0.6931 train_acc= 0.5071 val_loss= 0.6931 val_acc= 0.5167 time= 1.7422\n",
      "Epoch: 0004 train_loss= 0.6931 train_acc= 0.5071 val_loss= 0.6931 val_acc= 0.5167 time= 1.9400\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-3c63c7e0da36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Predict on full dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Train / validation scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m         return self._predict_loop(f, ins, batch_size=batch_size,\n\u001b[0;32m-> 1790\u001b[0;31m                                   verbose=verbose, steps=steps)\n\u001b[0m\u001b[1;32m   1791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1297\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m                     \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1299\u001b[0;31m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1300\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m                     \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sharonedayan/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Helper variables for main training loop\n",
    "wait = 0\n",
    "preds = None\n",
    "best_val_loss = 99999\n",
    "NB_EPOCH = 200\n",
    "PATIENCE = 10 # early stopping patience\n",
    "\n",
    "# Fit\n",
    "for epoch in range(1, NB_EPOCH+1):\n",
    "\n",
    "    # Log wall-clock time\n",
    "    t = time.time()\n",
    "\n",
    "    # Single training iteration (we mask nodes without labels for loss calculation)\n",
    "    model.fit(graph, y_train, sample_weight=train_mask,\n",
    "              batch_size=A.shape[0], epochs=1, shuffle=False, verbose=0)\n",
    "\n",
    "    # Predict on full dataset\n",
    "    preds = model.predict(graph, batch_size=A.shape[0])\n",
    "\n",
    "    # Train / validation scores\n",
    "    train_val_loss, train_val_acc = evaluate_preds(preds, [y_train, y_val],\n",
    "                                                   [idx_train, idx_val])\n",
    "    print(\"Epoch: {:04d}\".format(epoch),\n",
    "          \"train_loss= {:.4f}\".format(train_val_loss[0]),\n",
    "          \"train_acc= {:.4f}\".format(train_val_acc[0]),\n",
    "          \"val_loss= {:.4f}\".format(train_val_loss[1]),\n",
    "          \"val_acc= {:.4f}\".format(train_val_acc[1]),\n",
    "          \"time= {:.4f}\".format(time.time() - t))\n",
    "\n",
    "    # Early stopping\n",
    "    if train_val_loss[1] < best_val_loss:\n",
    "        best_val_loss = train_val_loss[1]\n",
    "        wait = 0\n",
    "    else:\n",
    "        if wait >= PATIENCE:\n",
    "            print('Epoch {}: early stopping'.format(epoch))\n",
    "            break\n",
    "        wait += 1\n",
    "\n",
    "# Testing\n",
    "test_loss, test_acc = evaluate_preds(preds, [y_test], [idx_test])\n",
    "print(\"Test set results:\",\n",
    "      \"loss= {:.4f}\".format(test_loss[0]),\n",
    "\"accuracy= {:.4f}\".format(test_acc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T10:43:16.718699Z",
     "start_time": "2017-12-28T10:43:16.714659Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If X contains randomly NaN values, what can we do to no have NaN predictions and a Nan loss ?  \n",
    "We see two to face this issue :\n",
    "- Fill NaN with 0.5 or the columns mean \n",
    "- Fill NaN with 0 and translate the other values (NaN->0, 0->1, 1->2) (https://www.kaggle.com/c/predict-west-nile-virus/discussion/13725#74831)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T11:07:26.452378Z",
     "start_time": "2017-12-28T11:07:26.449882Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nodes = 2500\n",
    "n_features = 600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First method for NaN : Translation and filling NaN with 0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T11:16:48.854682Z",
     "start_time": "2017-12-28T11:16:48.385122Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We randomly add nan values to X\n",
    "X = np.matrix(np.random.choice([0,1, np.nan], (nodes, n_features)))\n",
    "A = scipy.sparse.rand(nodes, nodes, density=0.4, format='csr')\n",
    "A.data[:] = 1\n",
    "# (nodes, 1) vector with the success\n",
    "y = np.random.choice([0,1], nodes).reshape((nodes, 1))\n",
    "# Converts a class vector to binary class matrix.\n",
    "y = to_categorical(y)\n",
    "\n",
    "y_train, y_val, y_test, idx_train, idx_val, idx_test, train_mask = get_splits(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T10:52:56.002823Z",
     "start_time": "2017-12-28T10:52:55.968577Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# translation\n",
    "X = X+1\n",
    "\n",
    "# Normalize X \n",
    "X = X/np.nansum(X,1).reshape(-1, 1)\n",
    "\n",
    "# filling NaN with 0s\n",
    "where_are_NaNs = np.isnan(X)\n",
    "X[where_are_NaNs] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T10:40:56.083299Z",
     "start_time": "2017-12-28T10:40:55.951510Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# local pool\n",
    "A_ = preprocess_adj(A, True)\n",
    "support = 1\n",
    "graph = [X, A_]\n",
    "G = [Input(shape=(None, None), batch_shape=(None, None), sparse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T10:40:57.989945Z",
     "start_time": "2017-12-28T10:40:57.879049Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_in = Input(shape=(X.shape[1],))\n",
    "\n",
    "# Define model architecture\n",
    "H = Dropout(0.5)(X_in)\n",
    "H = GraphConvolution(16, support, activation='relu', W_regularizer=l2(5e-4))([H]+G)\n",
    "H = Dropout(0.5)(H)\n",
    "Y = GraphConvolution(y.shape[1], support, activation='softmax')([H]+G)\n",
    "\n",
    "# Compile model\n",
    "model = Model(inputs=[X_in]+G, outputs=Y)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T10:42:07.147822Z",
     "start_time": "2017-12-28T10:41:45.784005Z"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 train_loss= 0.6923 train_acc= 0.5214 val_loss= 0.6905 val_acc= 0.5433 time= 0.7760\n",
      "Epoch: 0002 train_loss= 0.6923 train_acc= 0.5214 val_loss= 0.6905 val_acc= 0.5433 time= 0.7983\n",
      "Epoch: 0003 train_loss= 0.6923 train_acc= 0.5214 val_loss= 0.6905 val_acc= 0.5433 time= 0.7675\n",
      "Epoch: 0004 train_loss= 0.6923 train_acc= 0.5214 val_loss= 0.6905 val_acc= 0.5433 time= 0.7971\n",
      "Epoch: 0005 train_loss= 0.6923 train_acc= 0.5214 val_loss= 0.6905 val_acc= 0.5433 time= 0.7507\n",
      "Epoch: 0006 train_loss= 0.6923 train_acc= 0.5214 val_loss= 0.6905 val_acc= 0.5433 time= 0.7613\n",
      "Epoch: 0007 train_loss= 0.6923 train_acc= 0.5214 val_loss= 0.6906 val_acc= 0.5433 time= 0.7634\n",
      "Epoch: 0008 train_loss= 0.6923 train_acc= 0.5214 val_loss= 0.6904 val_acc= 0.5433 time= 0.7934\n",
      "Epoch: 0009 train_loss= 0.6923 train_acc= 0.5214 val_loss= 0.6904 val_acc= 0.5433 time= 0.8393\n",
      "Epoch: 0010 train_loss= 0.6923 train_acc= 0.5214 val_loss= 0.6904 val_acc= 0.5433 time= 0.8770\n",
      "Epoch: 0011 train_loss= 0.6923 train_acc= 0.5214 val_loss= 0.6905 val_acc= 0.5433 time= 0.7502\n",
      "Epoch: 0012 train_loss= 0.6923 train_acc= 0.5214 val_loss= 0.6905 val_acc= 0.5433 time= 0.7795\n",
      "Epoch: 0013 train_loss= 0.6923 train_acc= 0.5214 val_loss= 0.6905 val_acc= 0.5433 time= 0.7835\n",
      "Epoch: 0014 train_loss= 0.6923 train_acc= 0.5214 val_loss= 0.6903 val_acc= 0.5433 time= 0.7941\n",
      "Epoch: 0015 train_loss= 0.6923 train_acc= 0.5214 val_loss= 0.6903 val_acc= 0.5433 time= 0.8386\n",
      "Epoch: 0016 train_loss= 0.6923 train_acc= 0.5214 val_loss= 0.6904 val_acc= 0.5433 time= 0.8117\n",
      "Epoch: 0017 train_loss= 0.6923 train_acc= 0.5214 val_loss= 0.6906 val_acc= 0.5433 time= 0.8213\n",
      "Epoch: 0018 train_loss= 0.6923 train_acc= 0.5214 val_loss= 0.6906 val_acc= 0.5433 time= 0.8093\n",
      "Epoch: 0019 train_loss= 0.6923 train_acc= 0.5214 val_loss= 0.6905 val_acc= 0.5433 time= 0.8386\n",
      "Epoch: 0020 train_loss= 0.6923 train_acc= 0.5214 val_loss= 0.6904 val_acc= 0.5433 time= 0.8557\n",
      "Epoch: 0021 train_loss= 0.6923 train_acc= 0.5214 val_loss= 0.6903 val_acc= 0.5433 time= 0.8441\n",
      "Epoch: 0022 train_loss= 0.6923 train_acc= 0.5214 val_loss= 0.6904 val_acc= 0.5433 time= 0.8881\n",
      "Epoch: 0023 train_loss= 0.6923 train_acc= 0.5214 val_loss= 0.6906 val_acc= 0.5433 time= 0.8920\n",
      "Epoch: 0024 train_loss= 0.6923 train_acc= 0.5214 val_loss= 0.6905 val_acc= 0.5433 time= 0.8591\n",
      "Epoch: 0025 train_loss= 0.6923 train_acc= 0.5214 val_loss= 0.6904 val_acc= 0.5433 time= 0.9314\n",
      "Epoch: 0026 train_loss= 0.6923 train_acc= 0.5214 val_loss= 0.6903 val_acc= 0.5433 time= 0.8916\n",
      "Epoch 26: early stopping\n",
      "Test set results: loss= 0.6936 accuracy= 0.5050\n"
     ]
    }
   ],
   "source": [
    "# Helper variables for main training loop\n",
    "wait = 0\n",
    "preds = None\n",
    "best_val_loss = 99999\n",
    "NB_EPOCH = 200\n",
    "PATIENCE = 10 # early stopping patience\n",
    "\n",
    "# Fit\n",
    "for epoch in range(1, NB_EPOCH+1):\n",
    "\n",
    "    # Log wall-clock time\n",
    "    t = time.time()\n",
    "\n",
    "    # Single training iteration (we mask nodes without labels for loss calculation)\n",
    "    model.fit(graph, y_train, sample_weight=train_mask,\n",
    "              batch_size=A.shape[0], epochs=1, shuffle=False, verbose=0)\n",
    "\n",
    "    # Predict on full dataset\n",
    "    preds = model.predict(graph, batch_size=A.shape[0])\n",
    "\n",
    "    # Train / validation scores\n",
    "    train_val_loss, train_val_acc = evaluate_preds(preds, [y_train, y_val],\n",
    "                                                   [idx_train, idx_val])\n",
    "    print(\"Epoch: {:04d}\".format(epoch),\n",
    "          \"train_loss= {:.4f}\".format(train_val_loss[0]),\n",
    "          \"train_acc= {:.4f}\".format(train_val_acc[0]),\n",
    "          \"val_loss= {:.4f}\".format(train_val_loss[1]),\n",
    "          \"val_acc= {:.4f}\".format(train_val_acc[1]),\n",
    "          \"time= {:.4f}\".format(time.time() - t))\n",
    "\n",
    "    # Early stopping\n",
    "    if train_val_loss[1] <= best_val_loss:\n",
    "        best_val_loss = train_val_loss[1]\n",
    "        wait = 0\n",
    "    else:\n",
    "        if wait >= PATIENCE:\n",
    "            print('Epoch {}: early stopping'.format(epoch))\n",
    "            break\n",
    "        wait += 1\n",
    "\n",
    "# Testing\n",
    "test_loss, test_acc = evaluate_preds(preds, [y_test], [idx_test])\n",
    "print(\"Test set results:\",\n",
    "      \"loss= {:.4f}\".format(test_loss[0]),\n",
    "\"accuracy= {:.4f}\".format(test_acc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T10:42:12.679830Z",
     "start_time": "2017-12-28T10:42:12.676129Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.47942787,  0.52057219],\n",
       "       [ 0.48045942,  0.51954055],\n",
       "       [ 0.47922593,  0.52077407],\n",
       "       ..., \n",
       "       [ 0.47943738,  0.52056259],\n",
       "       [ 0.48083887,  0.51916116],\n",
       "       [ 0.48068473,  0.5193153 ]], dtype=float32)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T11:08:06.046782Z",
     "start_time": "2017-12-28T11:08:06.043229Z"
    }
   },
   "source": [
    "#### Second method for NaN : filling NaN with column means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We randomly add nan values to X\n",
    "X = np.matrix(np.random.choice([0,1, np.nan], (nodes, n_features)))\n",
    "A = scipy.sparse.rand(nodes, nodes, density=0.4, format='csr')\n",
    "A.data[:] = 1\n",
    "# (nodes, 1) vector with the success\n",
    "y = np.random.choice([0,1], nodes).reshape((nodes, 1))\n",
    "# Converts a class vector to binary class matrix.\n",
    "y = to_categorical(y)\n",
    "\n",
    "y_train, y_val, y_test, idx_train, idx_val, idx_test, train_mask = get_splits(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T11:10:16.992605Z",
     "start_time": "2017-12-28T11:10:16.954760Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_mean = np.nanmean(X, axis=0)\n",
    "#Find indicies that you need to replace\n",
    "inds = np.where(np.isnan(X))\n",
    "#Place column means in the indices. Align the arrays using take\n",
    "X[inds] = np.take(col_mean, inds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T11:10:34.374389Z",
     "start_time": "2017-12-28T11:10:34.243208Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# local pool\n",
    "A_ = preprocess_adj(A, True)\n",
    "support = 1\n",
    "graph = [X, A_]\n",
    "G = [Input(shape=(None, None), batch_shape=(None, None), sparse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T11:10:39.863070Z",
     "start_time": "2017-12-28T11:10:39.754051Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_in = Input(shape=(X.shape[1],))\n",
    "\n",
    "# Define model architecture\n",
    "H = Dropout(0.5)(X_in)\n",
    "H = GraphConvolution(16, support, activation='relu', W_regularizer=l2(5e-4))([H]+G)\n",
    "H = Dropout(0.5)(H)\n",
    "Y = GraphConvolution(y.shape[1], support, activation='softmax')([H]+G)\n",
    "\n",
    "# Compile model\n",
    "model = Model(inputs=[X_in]+G, outputs=Y)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T11:11:01.150496Z",
     "start_time": "2017-12-28T11:10:44.727543Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 train_loss= 1.3742 train_acc= 0.4857 val_loss= 1.2077 val_acc= 0.5533 time= 1.4730\n",
      "Epoch: 0002 train_loss= 0.8755 train_acc= 0.4857 val_loss= 0.7973 val_acc= 0.5533 time= 0.8854\n",
      "Epoch: 0003 train_loss= 0.7302 train_acc= 0.5143 val_loss= 0.7706 val_acc= 0.4467 time= 0.8353\n",
      "Epoch: 0004 train_loss= 0.6931 train_acc= 0.4857 val_loss= 0.6931 val_acc= 0.5533 time= 0.7949\n",
      "Epoch: 0005 train_loss= 0.6931 train_acc= 0.4857 val_loss= 0.6931 val_acc= 0.5533 time= 0.8277\n",
      "Epoch: 0006 train_loss= 0.6930 train_acc= 0.5143 val_loss= 0.6937 val_acc= 0.4467 time= 0.8052\n",
      "Epoch: 0007 train_loss= 0.8060 train_acc= 0.5143 val_loss= 0.8744 val_acc= 0.4467 time= 0.7911\n",
      "Epoch: 0008 train_loss= 0.6934 train_acc= 0.4857 val_loss= 0.6922 val_acc= 0.5533 time= 0.8231\n",
      "Epoch: 0009 train_loss= 0.6931 train_acc= 0.4857 val_loss= 0.6931 val_acc= 0.5533 time= 0.8885\n",
      "Epoch: 0010 train_loss= 0.6933 train_acc= 0.4857 val_loss= 0.6925 val_acc= 0.5533 time= 0.8608\n",
      "Epoch: 0011 train_loss= 0.6931 train_acc= 0.5143 val_loss= 0.6933 val_acc= 0.4467 time= 0.8005\n",
      "Epoch: 0012 train_loss= 0.7028 train_acc= 0.5143 val_loss= 0.7254 val_acc= 0.4467 time= 0.7778\n",
      "Epoch: 0013 train_loss= 0.6928 train_acc= 0.5143 val_loss= 0.6967 val_acc= 0.4467 time= 0.7800\n",
      "Epoch: 0014 train_loss= 0.6931 train_acc= 0.4857 val_loss= 0.6931 val_acc= 0.5533 time= 0.8290\n",
      "Epoch: 0015 train_loss= 0.6931 train_acc= 0.4857 val_loss= 0.6931 val_acc= 0.5533 time= 0.7896\n",
      "Epoch: 0016 train_loss= 0.6931 train_acc= 0.4857 val_loss= 0.6931 val_acc= 0.5533 time= 0.8367\n",
      "Epoch: 0017 train_loss= 0.6931 train_acc= 0.4857 val_loss= 0.6931 val_acc= 0.5533 time= 0.8158\n",
      "Epoch: 0018 train_loss= 0.6931 train_acc= 0.4857 val_loss= 0.6931 val_acc= 0.5533 time= 0.9065\n",
      "Epoch: 0019 train_loss= 0.6931 train_acc= 0.4857 val_loss= 0.6931 val_acc= 0.5533 time= 0.8489\n",
      "Epoch 19: early stopping\n",
      "Test set results: loss= 0.6931 accuracy= 0.4640\n"
     ]
    }
   ],
   "source": [
    "# Helper variables for main training loop\n",
    "wait = 0\n",
    "preds = None\n",
    "best_val_loss = 99999\n",
    "NB_EPOCH = 200\n",
    "PATIENCE = 10 # early stopping patience\n",
    "\n",
    "# Fit\n",
    "for epoch in range(1, NB_EPOCH+1):\n",
    "\n",
    "    # Log wall-clock time\n",
    "    t = time.time()\n",
    "\n",
    "    # Single training iteration (we mask nodes without labels for loss calculation)\n",
    "    model.fit(graph, y_train, sample_weight=train_mask,\n",
    "              batch_size=A.shape[0], epochs=1, shuffle=False, verbose=0)\n",
    "\n",
    "    # Predict on full dataset\n",
    "    preds = model.predict(graph, batch_size=A.shape[0])\n",
    "\n",
    "    # Train / validation scores\n",
    "    train_val_loss, train_val_acc = evaluate_preds(preds, [y_train, y_val],\n",
    "                                                   [idx_train, idx_val])\n",
    "    print(\"Epoch: {:04d}\".format(epoch),\n",
    "          \"train_loss= {:.4f}\".format(train_val_loss[0]),\n",
    "          \"train_acc= {:.4f}\".format(train_val_acc[0]),\n",
    "          \"val_loss= {:.4f}\".format(train_val_loss[1]),\n",
    "          \"val_acc= {:.4f}\".format(train_val_acc[1]),\n",
    "          \"time= {:.4f}\".format(time.time() - t))\n",
    "\n",
    "    # Early stopping\n",
    "    if train_val_loss[1] <= best_val_loss:\n",
    "        best_val_loss = train_val_loss[1]\n",
    "        wait = 0\n",
    "    else:\n",
    "        if wait >= PATIENCE:\n",
    "            print('Epoch {}: early stopping'.format(epoch))\n",
    "            break\n",
    "        wait += 1\n",
    "\n",
    "# Testing\n",
    "test_loss, test_acc = evaluate_preds(preds, [y_test], [idx_test])\n",
    "print(\"Test set results:\",\n",
    "      \"loss= {:.4f}\".format(test_loss[0]),\n",
    "\"accuracy= {:.4f}\".format(test_acc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T11:11:03.780823Z",
     "start_time": "2017-12-28T11:11:03.775539Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       ..., \n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0.5,  0.5]], dtype=float32)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
