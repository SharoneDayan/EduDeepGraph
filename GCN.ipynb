{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import time\n",
    "import sys\n",
    "sys.path.append('./gcn/gcn/')\n",
    "from utils import *\n",
    "import random\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "# Settings\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_float('learning_rate', 0.01, 'Initial learning rate.')\n",
    "flags.DEFINE_integer('epochs', 200, 'Number of epochs to train.')\n",
    "flags.DEFINE_integer('hidden1', 16, 'Number of units in hidden layer 1.')\n",
    "flags.DEFINE_float('dropout', 0.5, 'Dropout rate (1 - keep probability).')\n",
    "flags.DEFINE_float('weight_decay', 5e-4, 'Weight for L2 loss on embedding matrix.')\n",
    "flags.DEFINE_integer('early_stopping', 10, 'Tolerance for early stopping (# of epochs).')\n",
    "flags.DEFINE_integer('max_degree', 3, 'Maximum Chebyshev polynomial degree.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = pd.read_pickle('adjacency_small.pkl') \n",
    "H = pd.read_hdf('history_small.hdf', key='hist') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((878, 878), (878, 290))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape, H.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train_ = y_train[y_train.index.isin(idx)][idx_users]\n",
    "#features_ = features[features.index.isin(idx)]\n",
    "adj_ = adj[adj.index.isin(idx)][idx]\n",
    "train_mask_ = np.array(list(map(bool, np.ones(len(adj_)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#with open('y_train.pkl', 'wb') as f:\n",
    "#    pickle.dump(scipy.sparse.csr_matrix(y_train), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#y_train = hist + 1\n",
    "y_train_ = y_train_.values\n",
    "adj_[adj_<=0.3] = 0\n",
    "adj_ = scipy.sparse.csr_matrix(adj_.values)\n",
    "#features_ = scipy.sparse.lil.lil_matrix(features_.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 500), (1000, 1000), (1000,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_.shape, adj_.shape, train_mask_.shape #features_.shape, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#features_ = preprocess_features(features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "support_ = [preprocess_adj(adj_)]\n",
    "num_supports = 1\n",
    "model_func = GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define placeholders\n",
    "placeholders = {\n",
    "    'support': [tf.sparse_placeholder(tf.float32) for _ in range(num_supports)],\n",
    "    #'features': tf.sparse_placeholder(tf.float32, shape=tf.constant(features_[2], dtype=tf.int64)),\n",
    "    'labels': tf.placeholder(tf.float32, shape=(None, y_train_.shape[1])),\n",
    "    'labels_mask': tf.placeholder(tf.int32),\n",
    "    'dropout': tf.placeholder_with_default(0., shape=()),\n",
    "    'num_features_nonzero': tf.placeholder(tf.int32)  # helper variable for sparse dropout\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-e92c80b16b45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplaceholders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Initialize session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sharonedayan/Desktop/MVA/Graphs ML/PROJET/gcn/gcn/models.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, placeholders, input_dim, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGCN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplaceholders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;31m# self.input_dim = self.inputs.get_shape().as_list()[1]  # To be supported in future Tensorflow versions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'features'"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "model = model_func(placeholders, input_dim=y_train_[2][1], logging=True)\n",
    "\n",
    "# Initialize session\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define model evaluation function\n",
    "def evaluate(features, support, labels, mask, placeholders):\n",
    "    t_test = time.time()\n",
    "    feed_dict_val = construct_feed_dict(features, support, labels, mask, placeholders)\n",
    "    outs_val = sess.run([model.loss, model.accuracy], feed_dict=feed_dict_val)\n",
    "    return outs_val[0], outs_val[1], (time.time() - t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 train_loss= 59.15310 train_acc= 0.00000 val_loss= 59.08974 val_acc= 0.00000 time= 8.22234\n",
      "Epoch: 0002 train_loss= 59.09385 train_acc= 0.00000 val_loss= 59.02153 val_acc= 0.00000 time= 2.25967\n",
      "Epoch: 0003 train_loss= 59.02235 train_acc= 0.00000 val_loss= 58.94949 val_acc= 0.00000 time= 3.25773\n",
      "Epoch: 0004 train_loss= 58.95266 train_acc= 0.00000 val_loss= 58.87394 val_acc= 0.00000 time= 2.38136\n",
      "Epoch: 0005 train_loss= 58.87285 train_acc= 0.00000 val_loss= 58.79516 val_acc= 0.00000 time= 2.31219\n",
      "Epoch: 0006 train_loss= 58.79160 train_acc= 0.00000 val_loss= 58.71335 val_acc= 0.00000 time= 2.29659\n",
      "Epoch: 0007 train_loss= 58.71661 train_acc= 0.00000 val_loss= 58.62879 val_acc= 0.00000 time= 4.19655\n",
      "Epoch: 0008 train_loss= 58.67253 train_acc= 0.00000 val_loss= 58.54195 val_acc= 0.00000 time= 2.40630\n",
      "Epoch: 0009 train_loss= 58.52223 train_acc= 0.00000 val_loss= 58.45323 val_acc= 0.00000 time= 2.60343\n",
      "Epoch: 0010 train_loss= 58.48873 train_acc= 0.00000 val_loss= 58.36312 val_acc= 0.00000 time= 2.51278\n",
      "Epoch: 0011 train_loss= 58.41574 train_acc= 0.00000 val_loss= 58.27213 val_acc= 0.00000 time= 2.39931\n",
      "Epoch: 0012 train_loss= 58.23457 train_acc= 0.00000 val_loss= 58.18061 val_acc= 0.00000 time= 2.54289\n",
      "Epoch: 0013 train_loss= 58.17616 train_acc= 0.00000 val_loss= 58.08892 val_acc= 0.00000 time= 2.44286\n",
      "Epoch: 0014 train_loss= 58.07841 train_acc= 0.00000 val_loss= 57.99737 val_acc= 0.00000 time= 2.80924\n",
      "Epoch: 0015 train_loss= 57.96630 train_acc= 0.00000 val_loss= 57.90649 val_acc= 0.00000 time= 2.44948\n",
      "Epoch: 0016 train_loss= 57.88071 train_acc= 0.00000 val_loss= 57.81649 val_acc= 0.00000 time= 2.86223\n",
      "Epoch: 0017 train_loss= 57.79361 train_acc= 0.00000 val_loss= 57.72796 val_acc= 0.00000 time= 2.49811\n",
      "Epoch: 0018 train_loss= 57.73892 train_acc= 0.00000 val_loss= 57.64125 val_acc= 0.00000 time= 2.35400\n",
      "Epoch: 0019 train_loss= 57.63580 train_acc= 0.00000 val_loss= 57.55677 val_acc= 0.00000 time= 2.76341\n",
      "Epoch: 0020 train_loss= 57.60341 train_acc= 0.00000 val_loss= 57.47484 val_acc= 0.00000 time= 3.10534\n",
      "Epoch: 0021 train_loss= 57.45324 train_acc= 0.00000 val_loss= 57.39581 val_acc= 0.00000 time= 3.12543\n",
      "Epoch: 0022 train_loss= 57.40389 train_acc= 0.00000 val_loss= 57.31992 val_acc= 0.00000 time= 2.62063\n",
      "Epoch: 0023 train_loss= 57.29696 train_acc= 0.00000 val_loss= 57.24738 val_acc= 0.00000 time= 2.77974\n",
      "Epoch: 0024 train_loss= 57.27135 train_acc= 0.00000 val_loss= 57.17828 val_acc= 0.00000 time= 2.76707\n",
      "Epoch: 0025 train_loss= 57.22334 train_acc= 0.00000 val_loss= 57.11275 val_acc= 0.00000 time= 2.38610\n",
      "Epoch: 0026 train_loss= 57.12812 train_acc= 0.00000 val_loss= 57.05079 val_acc= 0.00000 time= 3.00894\n",
      "Epoch: 0027 train_loss= 57.09430 train_acc= 0.00000 val_loss= 56.99237 val_acc= 0.00000 time= 2.96717\n",
      "Epoch: 0028 train_loss= 57.00611 train_acc= 0.00000 val_loss= 56.93748 val_acc= 0.00000 time= 3.06085\n",
      "Epoch: 0029 train_loss= 56.97201 train_acc= 0.00000 val_loss= 56.88604 val_acc= 0.00000 time= 2.43919\n",
      "Epoch: 0030 train_loss= 56.88807 train_acc= 0.00000 val_loss= 56.83789 val_acc= 0.00000 time= 2.40363\n",
      "Epoch: 0031 train_loss= 56.80519 train_acc= 0.00000 val_loss= 56.79297 val_acc= 0.00000 time= 2.38152\n",
      "Epoch: 0032 train_loss= 56.79676 train_acc= 0.00000 val_loss= 56.75110 val_acc= 0.00000 time= 2.45673\n",
      "Epoch: 0033 train_loss= 56.79670 train_acc= 0.00700 val_loss= 56.71209 val_acc= 0.00000 time= 2.40812\n",
      "Epoch: 0034 train_loss= 56.72158 train_acc= 0.02000 val_loss= 56.67582 val_acc= 0.02000 time= 2.39927\n",
      "Epoch: 0035 train_loss= 56.66030 train_acc= 0.02000 val_loss= 56.64218 val_acc= 0.02000 time= 2.32911\n",
      "Epoch: 0036 train_loss= 56.64573 train_acc= 0.02000 val_loss= 56.61090 val_acc= 0.02000 time= 2.35714\n",
      "Epoch: 0037 train_loss= 56.61115 train_acc= 0.02000 val_loss= 56.58189 val_acc= 0.02000 time= 2.68595\n",
      "Epoch: 0038 train_loss= 56.58802 train_acc= 0.02000 val_loss= 56.55457 val_acc= 0.02000 time= 2.34370\n",
      "Epoch: 0039 train_loss= 56.55542 train_acc= 0.02000 val_loss= 56.52873 val_acc= 0.02000 time= 2.35201\n",
      "Epoch: 0040 train_loss= 56.57078 train_acc= 0.02000 val_loss= 56.50424 val_acc= 0.02000 time= 2.89838\n",
      "Epoch: 0041 train_loss= 56.45835 train_acc= 0.02000 val_loss= 56.48140 val_acc= 0.02000 time= 2.42829\n",
      "Epoch: 0042 train_loss= 56.46833 train_acc= 0.02000 val_loss= 56.46000 val_acc= 0.02000 time= 2.32397\n",
      "Epoch: 0043 train_loss= 56.45824 train_acc= 0.02000 val_loss= 56.43988 val_acc= 0.02000 time= 2.50986\n",
      "Epoch: 0044 train_loss= 56.42614 train_acc= 0.02000 val_loss= 56.42102 val_acc= 0.02000 time= 2.39553\n",
      "Epoch: 0045 train_loss= 56.42357 train_acc= 0.02000 val_loss= 56.40315 val_acc= 0.02000 time= 2.39343\n",
      "Epoch: 0046 train_loss= 56.41399 train_acc= 0.02000 val_loss= 56.38623 val_acc= 0.02000 time= 2.37842\n",
      "Epoch: 0047 train_loss= 56.38130 train_acc= 0.02000 val_loss= 56.37027 val_acc= 0.02000 time= 2.33364\n",
      "Epoch: 0048 train_loss= 56.35573 train_acc= 0.02000 val_loss= 56.35458 val_acc= 0.02000 time= 2.93123\n",
      "Epoch: 0049 train_loss= 56.36919 train_acc= 0.02000 val_loss= 56.33896 val_acc= 0.02000 time= 2.41472\n",
      "Epoch: 0050 train_loss= 56.35833 train_acc= 0.02000 val_loss= 56.32342 val_acc= 0.02000 time= 2.33147\n",
      "Epoch: 0051 train_loss= 56.30196 train_acc= 0.02000 val_loss= 56.30853 val_acc= 0.02000 time= 2.32547\n",
      "Epoch: 0052 train_loss= 56.31067 train_acc= 0.02000 val_loss= 56.29409 val_acc= 0.02000 time= 2.92444\n",
      "Epoch: 0053 train_loss= 56.29725 train_acc= 0.02000 val_loss= 56.28006 val_acc= 0.02000 time= 2.35684\n",
      "Epoch: 0054 train_loss= 56.27102 train_acc= 0.02000 val_loss= 56.26664 val_acc= 0.02000 time= 2.45983\n",
      "Epoch: 0055 train_loss= 56.27584 train_acc= 0.02000 val_loss= 56.25357 val_acc= 0.02000 time= 2.38025\n",
      "Epoch: 0056 train_loss= 56.26321 train_acc= 0.02000 val_loss= 56.24088 val_acc= 0.02000 time= 2.38444\n",
      "Epoch: 0057 train_loss= 56.22947 train_acc= 0.02000 val_loss= 56.22882 val_acc= 0.02000 time= 2.39134\n",
      "Epoch: 0058 train_loss= 56.23552 train_acc= 0.02000 val_loss= 56.21711 val_acc= 0.02000 time= 2.39928\n",
      "Epoch: 0059 train_loss= 56.22120 train_acc= 0.02000 val_loss= 56.20585 val_acc= 0.02000 time= 2.39784\n",
      "Epoch: 0060 train_loss= 56.19827 train_acc= 0.02000 val_loss= 56.19524 val_acc= 0.02000 time= 2.34257\n",
      "Epoch: 0061 train_loss= 56.21825 train_acc= 0.02000 val_loss= 56.18451 val_acc= 0.02000 time= 2.40850\n",
      "Epoch: 0062 train_loss= 56.19359 train_acc= 0.02000 val_loss= 56.17382 val_acc= 0.02000 time= 2.39336\n",
      "Epoch: 0063 train_loss= 56.18735 train_acc= 0.02000 val_loss= 56.16326 val_acc= 0.02000 time= 2.34777\n",
      "Epoch: 0064 train_loss= 56.16177 train_acc= 0.02000 val_loss= 56.15317 val_acc= 0.02000 time= 2.96885\n",
      "Epoch: 0065 train_loss= 56.16400 train_acc= 0.02000 val_loss= 56.14331 val_acc= 0.02000 time= 2.41578\n",
      "Epoch: 0066 train_loss= 56.15481 train_acc= 0.02000 val_loss= 56.13382 val_acc= 0.02000 time= 2.41565\n",
      "Epoch: 0067 train_loss= 56.12367 train_acc= 0.02000 val_loss= 56.12499 val_acc= 0.02000 time= 2.33806\n",
      "Epoch: 0068 train_loss= 56.12260 train_acc= 0.02000 val_loss= 56.11653 val_acc= 0.02000 time= 2.37735\n",
      "Epoch: 0069 train_loss= 56.13031 train_acc= 0.02000 val_loss= 56.10821 val_acc= 0.02000 time= 2.43953\n",
      "Epoch: 0070 train_loss= 56.09736 train_acc= 0.02000 val_loss= 56.10052 val_acc= 0.02000 time= 2.98862\n",
      "Epoch: 0071 train_loss= 56.09904 train_acc= 0.02000 val_loss= 56.09320 val_acc= 0.02000 time= 2.48618\n",
      "Epoch: 0072 train_loss= 56.07458 train_acc= 0.02000 val_loss= 56.08656 val_acc= 0.02000 time= 2.33811\n",
      "Epoch: 0073 train_loss= 56.10160 train_acc= 0.02000 val_loss= 56.07957 val_acc= 0.02000 time= 3.29841\n",
      "Epoch: 0074 train_loss= 56.08762 train_acc= 0.02000 val_loss= 56.07259 val_acc= 0.02000 time= 3.11633\n",
      "Epoch: 0075 train_loss= 56.05370 train_acc= 0.02000 val_loss= 56.06610 val_acc= 0.02000 time= 2.72819\n",
      "Epoch: 0076 train_loss= 56.03065 train_acc= 0.02000 val_loss= 56.06067 val_acc= 0.02000 time= 3.47006\n",
      "Epoch: 0077 train_loss= 56.05255 train_acc= 0.02000 val_loss= 56.05544 val_acc= 0.02000 time= 2.64873\n",
      "Epoch: 0078 train_loss= 56.06844 train_acc= 0.02000 val_loss= 56.04997 val_acc= 0.02000 time= 2.55033\n",
      "Epoch: 0079 train_loss= 56.03860 train_acc= 0.02000 val_loss= 56.04483 val_acc= 0.02000 time= 2.67711\n",
      "Epoch: 0080 train_loss= 56.04125 train_acc= 0.02000 val_loss= 56.03975 val_acc= 0.02000 time= 3.44979\n",
      "Epoch: 0081 train_loss= 56.06577 train_acc= 0.02000 val_loss= 56.03378 val_acc= 0.02000 time= 3.02925\n",
      "Epoch: 0082 train_loss= 56.02192 train_acc= 0.02000 val_loss= 56.02829 val_acc= 0.02000 time= 2.40090\n",
      "Epoch: 0083 train_loss= 56.02759 train_acc= 0.02000 val_loss= 56.02334 val_acc= 0.02000 time= 2.33756\n",
      "Epoch: 0084 train_loss= 56.00507 train_acc= 0.02000 val_loss= 56.01934 val_acc= 0.02000 time= 2.38103\n",
      "Epoch: 0085 train_loss= 55.99099 train_acc= 0.02000 val_loss= 56.01672 val_acc= 0.02000 time= 2.40212\n",
      "Epoch: 0086 train_loss= 55.99553 train_acc= 0.02000 val_loss= 56.01480 val_acc= 0.02000 time= 2.33707\n",
      "Epoch: 0087 train_loss= 56.03734 train_acc= 0.02000 val_loss= 56.01170 val_acc= 0.02000 time= 2.60631\n",
      "Epoch: 0088 train_loss= 56.00367 train_acc= 0.02000 val_loss= 56.00856 val_acc= 0.02000 time= 2.33953\n",
      "Epoch: 0089 train_loss= 56.00632 train_acc= 0.02000 val_loss= 56.00535 val_acc= 0.02000 time= 2.31608\n",
      "Epoch: 0090 train_loss= 56.03130 train_acc= 0.02000 val_loss= 56.00034 val_acc= 0.02000 time= 2.67676\n",
      "Epoch: 0091 train_loss= 55.99254 train_acc= 0.02000 val_loss= 55.99619 val_acc= 0.02000 time= 2.46604\n",
      "Epoch: 0092 train_loss= 55.96796 train_acc= 0.02000 val_loss= 55.99347 val_acc= 0.02000 time= 2.31162\n",
      "Epoch: 0093 train_loss= 55.97410 train_acc= 0.02000 val_loss= 55.99179 val_acc= 0.02000 time= 2.38019\n",
      "Epoch: 0094 train_loss= 55.96094 train_acc= 0.02000 val_loss= 55.99163 val_acc= 0.02000 time= 2.33237\n",
      "Epoch: 0095 train_loss= 55.99110 train_acc= 0.02000 val_loss= 55.99065 val_acc= 0.02000 time= 2.37820\n",
      "Epoch: 0096 train_loss= 56.02052 train_acc= 0.02000 val_loss= 55.98737 val_acc= 0.02000 time= 2.38698\n",
      "Epoch: 0097 train_loss= 55.98143 train_acc= 0.02000 val_loss= 55.98389 val_acc= 0.02000 time= 2.30473\n",
      "Epoch: 0098 train_loss= 55.98950 train_acc= 0.02000 val_loss= 55.98030 val_acc= 0.02000 time= 2.33790\n",
      "Epoch: 0099 train_loss= 55.98504 train_acc= 0.02000 val_loss= 55.97704 val_acc= 0.02000 time= 2.59557\n",
      "Epoch: 0100 train_loss= 55.98780 train_acc= 0.02000 val_loss= 55.97395 val_acc= 0.02000 time= 2.96081\n",
      "Epoch: 0101 train_loss= 55.97856 train_acc= 0.02000 val_loss= 55.97153 val_acc= 0.02000 time= 2.34109\n",
      "Epoch: 0102 train_loss= 55.97665 train_acc= 0.02000 val_loss= 55.97009 val_acc= 0.02000 time= 2.33975\n",
      "Epoch: 0103 train_loss= 55.97364 train_acc= 0.02000 val_loss= 55.96916 val_acc= 0.02000 time= 2.34884\n",
      "Epoch: 0104 train_loss= 55.95819 train_acc= 0.02000 val_loss= 55.96952 val_acc= 0.02000 time= 2.34981\n",
      "Epoch: 0105 train_loss= 55.95912 train_acc= 0.02000 val_loss= 55.97117 val_acc= 0.02000 time= 2.32054\n",
      "Epoch: 0106 train_loss= 55.98480 train_acc= 0.02000 val_loss= 55.97197 val_acc= 0.02000 time= 2.39830\n",
      "Epoch: 0107 train_loss= 55.97662 train_acc= 0.02000 val_loss= 55.97124 val_acc= 0.02000 time= 2.39882\n",
      "Epoch: 0108 train_loss= 55.98433 train_acc= 0.02000 val_loss= 55.96990 val_acc= 0.02000 time= 2.34608\n",
      "Epoch: 0109 train_loss= 55.98867 train_acc= 0.02000 val_loss= 55.96836 val_acc= 0.02000 time= 2.59519\n",
      "Epoch: 0110 train_loss= 55.97999 train_acc= 0.02000 val_loss= 55.96684 val_acc= 0.02000 time= 4.16753\n",
      "Epoch: 0111 train_loss= 55.94899 train_acc= 0.02000 val_loss= 55.96799 val_acc= 0.02000 time= 2.70431\n",
      "Epoch: 0112 train_loss= 55.96139 train_acc= 0.02000 val_loss= 55.97026 val_acc= 0.02000 time= 2.32683\n",
      "Early stopping...\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "# Init variables\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "cost_val = []\n",
    "\n",
    "# Train model\n",
    "for epoch in range(FLAGS.epochs):\n",
    "\n",
    "    t = time.time()\n",
    "    # Construct feed dictionary\n",
    "    feed_dict = construct_feed_dict(features_, support_, y_train_, train_mask_, placeholders)\n",
    "    feed_dict.update({placeholders['dropout']: FLAGS.dropout})\n",
    "\n",
    "    # Training step\n",
    "    outs = sess.run([model.opt_op, model.loss, model.accuracy], feed_dict=feed_dict)\n",
    "\n",
    "    # Validation\n",
    "    cost, acc, duration = evaluate(features_, support_, y_train_, train_mask_, placeholders)\n",
    "    cost_val.append(cost)\n",
    "\n",
    "    # Print results\n",
    "    print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(outs[1]),\n",
    "          \"train_acc=\", \"{:.5f}\".format(outs[2]), \"val_loss=\", \"{:.5f}\".format(cost),\n",
    "          \"val_acc=\", \"{:.5f}\".format(acc), \"time=\", \"{:.5f}\".format(time.time() - t))\n",
    "\n",
    "    if epoch > FLAGS.early_stopping and cost_val[-1] > np.mean(cost_val[-(FLAGS.early_stopping+1):-1]):\n",
    "        print(\"Early stopping...\")\n",
    "        break\n",
    "\n",
    "print(\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05395676642475205"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(59.15310 - 55.96139 )/59.15310"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
