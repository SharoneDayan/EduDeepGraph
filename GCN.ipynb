{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T16:25:12.659323Z",
     "start_time": "2017-12-27T16:25:10.369891Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/attia/Desktop/Work/workenv/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import time\n",
    "import sys\n",
    "# Import T. Kipf's GCN implementation\n",
    "# https://github.com/tkipf/gcn\n",
    "sys.path.append('../gcn/gcn/')\n",
    "from utils import *\n",
    "import random\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data, configuration and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T16:27:03.103879Z",
     "start_time": "2017-12-27T16:27:03.096268Z"
    }
   },
   "outputs": [],
   "source": [
    "# Settings\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_float('learning_rate', 0.01, 'Initial learning rate.')\n",
    "flags.DEFINE_integer('epochs', 200, 'Number of epochs to train.')\n",
    "flags.DEFINE_integer('hidden1', 16, 'Number of units in hidden layer 1.')\n",
    "flags.DEFINE_float('dropout', 0.5, 'Dropout rate (1 - keep probability).')\n",
    "flags.DEFINE_float('weight_decay', 5e-4, 'Weight for L2 loss on embedding matrix.')\n",
    "flags.DEFINE_integer('early_stopping', 10, 'Tolerance for early stopping (# of epochs).')\n",
    "flags.DEFINE_integer('max_degree', 3, 'Maximum Chebyshev polynomial degree.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T17:30:38.562222Z",
     "start_time": "2017-12-27T17:30:38.546296Z"
    }
   },
   "outputs": [],
   "source": [
    "W = pd.read_pickle('adjacency_small.pkl') \n",
    "H = pd.read_hdf('history_small.hdf', key='hist') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T17:30:38.854558Z",
     "start_time": "2017-12-27T17:30:38.840276Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Translate values to have a sparser matrix\n",
    "H[H == 0] = 100\n",
    "H[H == 1] = 101\n",
    "H[H == -100] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T17:30:39.226875Z",
     "start_time": "2017-12-27T17:30:39.205163Z"
    }
   },
   "outputs": [],
   "source": [
    "## Preprocessing History Matrix (n x m)\n",
    "# Converting to float for matrix powers\n",
    "H = H.astype(np.float16)\n",
    "# Thresholding\n",
    "W[W<0.3] = 0\n",
    "# Convert to lil - matrix\n",
    "H = scipy.sparse.lil.lil_matrix(H.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T17:30:39.716935Z",
     "start_time": "2017-12-27T17:30:39.625761Z"
    }
   },
   "outputs": [],
   "source": [
    "## Preprocessing Adjacency Matrix (n x n)\n",
    "W = scipy.sparse.csr_matrix(W.values)\n",
    "support = [preprocess_adj(W)]\n",
    "num_supports = 1\n",
    "model_func = GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T17:33:00.151432Z",
     "start_time": "2017-12-27T17:33:00.148888Z"
    }
   },
   "outputs": [],
   "source": [
    "## TO DO :\n",
    "## How to define the correct placeholder corresponding to the ones\n",
    "## used by T. Kipf : \n",
    "## labels = H.values.flatten() ie a n x m vector ? What's the point to use H.values.flatten() and H ?\n",
    "## features = H ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T17:31:20.167085Z",
     "start_time": "2017-12-27T17:31:20.160762Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define placeholders\n",
    "placeholders = {\n",
    "    #'support': [tf.sparse_placeholder(tf.float32) for _ in range(num_supports)],\n",
    "    #'features': tf.sparse_placeholder(tf.float32, shape=tf.constant(H[2], dtype=tf.int64)),\n",
    "    #'labels': tf.placeholder(tf.float32, shape=(None, y_train_.shape[1])),\n",
    "    'labels_mask': tf.placeholder(tf.int32),\n",
    "    'dropout': tf.placeholder_with_default(0., shape=()),\n",
    "    'num_features_nonzero': tf.placeholder(tf.int32)  # helper variable for sparse dropout\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T17:33:31.106391Z",
     "start_time": "2017-12-27T17:33:31.103867Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = model_func(placeholders, input_dim=y_train_[2][1], logging=True)\n",
    "\n",
    "# Initialize session\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model evaluation function\n",
    "def evaluate(features, support, labels, mask, placeholders):\n",
    "    t_test = time.time()\n",
    "    feed_dict_val = construct_feed_dict(features, support, labels, mask, placeholders)\n",
    "    outs_val = sess.run([model.loss, model.accuracy], feed_dict=feed_dict_val)\n",
    "    return outs_val[0], outs_val[1], (time.time() - t_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T17:34:03.116373Z",
     "start_time": "2017-12-27T17:34:03.109650Z"
    }
   },
   "outputs": [],
   "source": [
    "# Init variables\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "cost_val = []\n",
    "\n",
    "# Train model\n",
    "for epoch in range(FLAGS.epochs):\n",
    "\n",
    "    t = time.time()\n",
    "    # Construct feed dictionary\n",
    "    feed_dict = construct_feed_dict(features_, support_, y_train_, train_mask_, placeholders)\n",
    "    feed_dict.update({placeholders['dropout']: FLAGS.dropout})\n",
    "\n",
    "    # Training step\n",
    "    outs = sess.run([model.opt_op, model.loss, model.accuracy], feed_dict=feed_dict)\n",
    "\n",
    "    # Validation\n",
    "    cost, acc, duration = evaluate(features_, support_, y_train_, train_mask_, placeholders)\n",
    "    cost_val.append(cost)\n",
    "\n",
    "    # Print results\n",
    "    print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(outs[1]),\n",
    "          \"train_acc=\", \"{:.5f}\".format(outs[2]), \"val_loss=\", \"{:.5f}\".format(cost),\n",
    "          \"val_acc=\", \"{:.5f}\".format(acc), \"time=\", \"{:.5f}\".format(time.time() - t))\n",
    "\n",
    "    if epoch > FLAGS.early_stopping and cost_val[-1] > np.mean(cost_val[-(FLAGS.early_stopping+1):-1]):\n",
    "        print(\"Early stopping...\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
